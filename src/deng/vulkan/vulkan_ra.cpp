/*    ____         ________     __      _        ______  
 *   |  _ \_      |  ______|   |  \    | |     _/  ____\
 *   | | \_ \_    |  |         |   \   | |    /  _/   
 *   | |   \  |   |  |_____    | |\ \  | |   |  |   _____ 
 *   | |    | |   |  ______|   | | \ \ | |   |  |  |___  | 
 *   | |  _/ _|   |  |         | |  \ \| |    \  \    / /
 *   | |_/ _/     |  |_____    | |   \   |     \_ \__/ /
 *   |____/       |________|   |_|    \__|       \____/
 *               
 * __________________________________________________________
 * __________________________________________________________
 *                       Project DENG 
 *
 *
 * Copyright (C) 2020 - 2021
 * This Software is licensed under Apache License as described 
 * in the LICENSE.md file, which you should have recieved with 
 * this distribution.
 * 
 * You may reproduce and distribute copies of the
 * Work or Derivative Works thereof in any medium, with or without
 * modifications, and in Source or Object form, provided that You
 * meet the following conditions:
 *
 * (a) You must give any other recipients of the Work or
 *     Derivative Works a copy of this License; and
 *
 * (b) You must cause any modified files to carry prominent notices
 *     stating that You changed the files; and
 *
 * (c) You must retain, in the Source form of any Derivative Works
 *     that You distribute, all copyright, patent, trademark, and
 *     attribution notices from the Source form of the Work,
 *     excluding those notices that do not pertain to any part of
 *     the Derivative Works; and
 *
 * (d) If the Work includes a "NOTICE" text file as part of its
 *     distribution, then any Derivative Works that You distribute must
 *     include a readable copy of the attribution notices contained
 *     within such NOTICE file, excluding those notices that do not
 *     pertain to any part of the Derivative Works, in at least one
 *     of the following places: within a NOTICE text file distributed
 *     as part of the Derivative Works; within the Source form or
 *     documentation, if provided along with the Derivative Works; or,
 *     within a display generated by the Derivative Works, if and
 *     wherever such third-party notices normally appear. The contents
 *     of the NOTICE file are for informational purposes only and
 *     do not modify the License. You may add Your own attribution
 *     notices within Derivative Works that You distribute, alongside
 *     or as an addendum to the NOTICE text from the Work, provided
 *     that such additional attribution notices cannot be construed
 *     as modifying the License.
 *
 * You may add Your own copyright statement to Your modifications and
 * may provide additional or different license terms and conditions
 * for use, reproduction, or distribution of Your modifications, or
 * for any such Derivative Works as a whole, provided Your use,
 * reproduction, and distribution of the Work otherwise complies with
 * the conditions stated in this License.
 */ 


#define __VULKAN_RA_CPP
#include <deng/vulkan/vulkan_ra.h>

namespace deng {
    namespace vulkan {
        extern deng_ui32_t __max_frame_c;       

        /*********************************************************/
        /*********************************************************/
        /********** __vk_TextureAllocator class methods **********/
        /*********************************************************/
        /*********************************************************/

        __vk_TextureAllocator::__vk_TextureAllocator (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue,
            size_t sc_img_size,
            std::vector<__vk_Texture> *p_tex,
            Hashmap *p_tex_map
        ) {
            m_p_textures = p_tex;
            m_p_tex_map = p_tex_map;

            // Create dummy texture instance
            __mkDummyTex (
                device,
                gpu,
                cmd_pool,
                g_queue
            );

            // Allocate memory for new texture image memory instance
            __allocateTexMemory (
                device,
                gpu,
                cmd_pool,
                g_queue,
                0,
                __DEFAULT_TEX_MEM_CAP
            );
        }


        /*
         * Create dummy texture in case any texture mapped asset
         * has invalid texture uuid
         */
        void __vk_TextureAllocator::__mkDummyTex (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue
        ) {
            size_t i = m_p_textures->size();
            m_p_textures->resize(i + 1);
            m_p_textures->at(i).texture.name = (char*) "dummy";
            m_p_textures->at(i).texture.uuid = uuid_Generate();
            m_dummy_tex_uuid = m_p_textures->at(i).texture.uuid;
            LOG("Dummy texture generation uuid: " + std::string(m_dummy_tex_uuid));
            m_p_textures->at(i).texture.pixel_data.width = __DEFAULT_TEX_WIDTH;
            m_p_textures->at(i).texture.pixel_data.height = __DEFAULT_TEX_HEIGHT;
            m_p_textures->at(i).texture.pixel_data.size = __DEFAULT_TEX_SIZE;

            m_p_textures->at(i).texture.pixel_data.p_pixel_data = (deng_ui8_t*) malloc(__DEFAULT_TEX_SIZE);
            memset(m_p_textures->at(i).texture.pixel_data.p_pixel_data, 255, __DEFAULT_TEX_SIZE);

            pushToHashmap (
                m_p_tex_map,
                m_dummy_tex_uuid,
                strlen(m_dummy_tex_uuid),
                &m_p_textures->at(i)
            );

            __newImage (
                device,
                gpu,
                cmd_pool,
                g_queue,
                1,
                false,
                m_p_textures->at(i)
            );
        }


        /*
         * Create mipmaps for texture images
         */
        void __vk_TextureAllocator::__mkMipMaps (
            VkDevice &device,
            VkCommandPool &cmd_pool,
            VkImage image,
            VkQueue g_queue,
            deng_i32_t width,
            deng_i32_t height,
            deng_ui32_t mip_levels
        ) {
            // Generate all mipmaps
            VkCommandBuffer cmd_buf;
            __vk_CommandBufferRecorder::beginCommandBufferSingleCommand (
                device,
                cmd_pool,
                &cmd_buf
            );

            VkImageMemoryBarrier mem_barrier{};
            VkImageBlit blit{};
            mem_barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
            mem_barrier.image = image;
            mem_barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
            mem_barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
            mem_barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
            mem_barrier.subresourceRange.baseArrayLayer = 0;
            mem_barrier.subresourceRange.layerCount = 1;
            mem_barrier.subresourceRange.levelCount = 1;

            deng_i32_t mip_width = width;
            deng_i32_t mip_height = height;
            deng_ui32_t index;
            for(index = 1; index < mip_levels; index++) {
                mem_barrier.subresourceRange.baseMipLevel = index - 1;
                mem_barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
                mem_barrier.newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
                mem_barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
                mem_barrier.dstAccessMask = VK_ACCESS_TRANSFER_READ_BIT;

                // Record pipeline barrier
                vkCmdPipelineBarrier (
                    cmd_buf,
                    VK_PIPELINE_STAGE_TRANSFER_BIT,
                    VK_PIPELINE_STAGE_TRANSFER_BIT,
                    0,
                    0,
                    NULL,
                    0,
                    NULL,
                    1,
                    &mem_barrier
                );

                // Set blit image struct for mipmapping
                blit.srcOffsets[0] = {0, 0, 0};
                blit.srcOffsets[1] = {mip_width, mip_height, 1};
                blit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
                blit.srcSubresource.baseArrayLayer = 0;
                blit.srcSubresource.mipLevel = index - 1;
                blit.srcSubresource.layerCount = 1;
                blit.dstOffsets[0] = {0, 0, 0};
                blit.dstOffsets[1] = {mip_width > 1 ? mip_width / 2 : 1, mip_height > 1 ? mip_height / 2 : 1, 1};
                blit.dstSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
                blit.dstSubresource.baseArrayLayer = 0;
                blit.dstSubresource.mipLevel = index;
                blit.dstSubresource.layerCount = 1;

                vkCmdBlitImage (
                    cmd_buf,
                    image,
                    VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
                    image, 
                    VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
                    1,
                    &blit,
                    VK_FILTER_LINEAR
                );

                mem_barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
                mem_barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
                mem_barrier.srcAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
                mem_barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

                vkCmdPipelineBarrier (
                    cmd_buf,
                    VK_PIPELINE_STAGE_TRANSFER_BIT,
                    VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,
                    0,
                    0,
                    NULL,
                    0,
                    NULL,
                    1,
                    &mem_barrier
                );

                if(mip_width > 1) mip_width /= 2;
                if(mip_height > 1) mip_height /= 2;
            }

            // Final mip level transitioning
            mem_barrier.subresourceRange.baseMipLevel = mip_levels - 1;
            mem_barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
            mem_barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
            mem_barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
            mem_barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;

            vkCmdPipelineBarrier (
                cmd_buf,
                VK_PIPELINE_STAGE_TRANSFER_BIT,
                VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,
                0,
                0,
                NULL,
                0,
                NULL,
                1,
                &mem_barrier
            );

            __vk_CommandBufferRecorder::endCommandBufferSingleCommand (
                device,
                g_queue,
                cmd_pool,
                &cmd_buf
            );
        }


        /*
         * Create texture sampler for texture image
         */
        void __vk_TextureAllocator::__mkTextureSampler (
            VkDevice &device,
            VkSampler &sampler,
            deng_ui32_t mip_levels
        ) {
            // Set up texture sampler createinfo base
            VkSamplerCreateInfo sampler_info{};
            sampler_info.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
            sampler_info.magFilter = VK_FILTER_LINEAR;
            sampler_info.minFilter = VK_FILTER_LINEAR;
            sampler_info.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT;
            sampler_info.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT;
            sampler_info.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT;
            sampler_info.anisotropyEnable = VK_TRUE;
            sampler_info.maxAnisotropy = 16.0f;
            sampler_info.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;
            sampler_info.unnormalizedCoordinates = VK_FALSE;
            sampler_info.compareEnable = VK_FALSE;
            sampler_info.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
            sampler_info.mipLodBias = 0.0f;
            sampler_info.minLod = 0.0f;
            sampler_info.maxLod = static_cast<deng_vec_t>(mip_levels);

            // Create texture sampler 
            if(vkCreateSampler(device, &sampler_info, NULL, &sampler) != VK_SUCCESS)
                VK_RES_ERR("failed to create texture sampler!");
        }


        /*
         * Allocate memory for texture buffers
         * req_size must be larger than the memory required for all textures combined
         */
        void __vk_TextureAllocator::__allocateTexMemory (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool, 
            VkQueue g_queue, 
            VkDeviceSize old_size,
            VkDeviceSize req_size
        ) {
            m_buffer_data.img_memory_cap = req_size;

            // VkBuffer object is needed for copying staging buffer data to 
            // texture buffer 
            VkBuffer dst_buf;
            __vk_BufferCreator::makeBuffer (
                device,
                gpu, 
                req_size, 
                VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT,
                dst_buf
            );

            // Check if memory was used before 
            if(old_size) {
                // Create staging buffer to store data for reallocating 
                // texture buffer memory
                VkMemoryRequirements mem_req = __vk_BufferCreator::makeBuffer (
                    device,
                    gpu,
                    m_buffer_data.img_memory_cap,
                    VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                    m_buffer_data.staging_buffer
                );

                // Allocate memory for staging buffer
                __vk_BufferCreator::allocateMemory (
                    device, 
                    gpu,
                    mem_req.size,
                    m_buffer_data.staging_buffer_memory,
                    mem_req.memoryTypeBits,
                    VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                    VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
                );

                // Bind staging buffer to staging memory
                vkBindBufferMemory (
                    device,
                    m_buffer_data.staging_buffer,
                    m_buffer_data.staging_buffer_memory,
                    0
                );

                // Copy old data from image buffer memory to new staging buffer
                void *data = NULL;
                vkMapMemory (
                    device, 
                    m_buffer_data.img_memory, 
                    0, 
                    old_size, 
                    0, 
                    &data
                );
                    __vk_BufferCreator::cpyToBufferMem (
                        device,
                        old_size,
                        data,
                        m_buffer_data.staging_buffer_memory,
                        0
                    );

                vkUnmapMemory (
                    device,
                    m_buffer_data.img_memory
                );

                // Allocate memory for new texture image data buffer
                __vk_BufferCreator::allocateMemory (
                    device,
                    gpu,
                    req_size,
                    m_buffer_data.img_memory,
                    m_tex_mem_bits,
                    VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
                );

                // Bind memory with dst_buf
                vkBindBufferMemory (
                    device, 
                    dst_buf,
                    m_buffer_data.img_memory,
                    0
                );

                // Copy the contents of staging buffer to image buffer
                __vk_BufferCreator::cpyBufferToBuffer (
                    device, 
                    cmd_pool, 
                    g_queue, 
                    m_buffer_data.staging_buffer,
                    dst_buf,
                    old_size,
                    0
                );

                // Destroy all buffer handles
                vkDestroyBuffer(device, m_buffer_data.staging_buffer, NULL);
                vkDestroyBuffer(device, dst_buf, NULL);
                vkFreeMemory(device, m_buffer_data.staging_buffer_memory, NULL);
            }

            // Allocate new memory for new texture image buffer
            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                req_size,
                m_buffer_data.img_memory,
                m_tex_mem_bits,
                VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
            );
        }


        /*
         * Create new VkImage and VkImageView instances for single texture
         * This method expects that enough memory is allocated for bitmap data
         * of the given texture
         */
        void __vk_TextureAllocator::__newImage (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue,
            deng_ui32_t mip_levels,
            deng_bool_t is_lf,
            __vk_Texture &tex
        ) {
            // Create staging buffer
            VkMemoryRequirements mem_req = __vk_BufferCreator::makeBuffer (
                device,
                gpu,
                tex.texture.pixel_data.size,
                VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                m_buffer_data.staging_buffer
            );

            // Allocate memory for staging buffer
            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                mem_req.size,
                m_buffer_data.staging_buffer_memory,
                mem_req.memoryTypeBits,
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
            );

            // Bind staging buffer to its memory
            vkBindBufferMemory (
                device,
                m_buffer_data.staging_buffer,
                m_buffer_data.staging_buffer_memory,
                0
            );

            // Copy all bitmap data to staging buffer
            __vk_BufferCreator::cpyToBufferMem (
                device,
                tex.texture.pixel_data.size,
                tex.texture.pixel_data.p_pixel_data,
                m_buffer_data.staging_buffer_memory,
                0
            );

            tex.texture.pixel_data.memory_offset = m_buffer_data.img_memory_offset;

            // Create new VkImage instance
            LOG("TEX width, height: " + std::to_string(tex.texture.pixel_data.width) + ";" + std::to_string(tex.texture.pixel_data.height));
            mem_req = __vk_ImageCreator::makeImage (
                device,
                gpu,
                tex.image,
                (deng_ui32_t) tex.texture.pixel_data.width,
                (deng_ui32_t) tex.texture.pixel_data.height, 
                mip_levels,
                VK_FORMAT_B8G8R8A8_SRGB,
                VK_IMAGE_TILING_OPTIMAL,
                VK_IMAGE_USAGE_SAMPLED_BIT |
                VK_IMAGE_USAGE_TRANSFER_DST_BIT |
                VK_IMAGE_USAGE_TRANSFER_SRC_BIT,
                VK_SAMPLE_COUNT_1_BIT
            );
            
            // Check if image memory needs to be allocated
            if(m_buffer_data.img_memory_offset + mem_req.size > m_buffer_data.img_memory_cap) {
                VkDeviceSize req_size;
                if(!m_buffer_data.img_memory_cap) {
                    m_tex_mem_bits = mem_req.memoryTypeBits;
                    LOG("Detected no capacity for texture images");
                    req_size = 4194304;
                }
                else {
                    req_size = m_buffer_data.img_memory_cap * 2 > m_buffer_data.img_memory_offset + mem_req.size ?
                                            m_buffer_data.img_memory_cap * 2 :
                                            (m_buffer_data.img_memory_offset + mem_req.size) * 2;
                }
                __allocateTexMemory (
                    device, 
                    gpu, 
                    cmd_pool, 
                    g_queue, 
                    m_buffer_data.img_memory_cap,
                    req_size
                );
            }
            
            m_buffer_data.img_memory_offset += mem_req.size;

            // Bind the image to its memory with correct offsets
            vkBindImageMemory (
                device,
                tex.image,
                m_buffer_data.img_memory,
                tex.texture.pixel_data.memory_offset
            );

            // Transition image layout for copying from staging buffer
            __vk_ImageCreator::transitionImageLayout (
                device,
                tex.image,
                cmd_pool,
                g_queue,
                VK_FORMAT_B8G8R8A8_SRGB,
                VK_IMAGE_LAYOUT_UNDEFINED,
                VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
                mip_levels
            );

            // Copy data from staging buffer to image buffer
            __vk_ImageCreator::cpyBufferToImage (
                device,
                cmd_pool,
                g_queue,
                m_buffer_data.staging_buffer,
                tex.image,
                tex.texture.pixel_data.width,
                tex.texture.pixel_data.height
            );

            // Additional mipmap enable / disable flags should be implemented
            if(is_lf) {
                __mkMipMaps (
                    device,
                    cmd_pool,
                    tex.image,
                    g_queue,
                    (deng_i32_t) tex.texture.pixel_data.width,
                    (deng_i32_t) tex.texture.pixel_data.height,
                    mip_levels
                );
            }

            else {
                __vk_ImageCreator::transitionImageLayout (
                    device,
                    tex.image,
                    cmd_pool,
                    g_queue,
                    VK_FORMAT_B8G8R8A8_SRGB,
                    VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
                    VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
                    mip_levels
                );
            }

            // Clean the staging buffer
            vkDestroyBuffer (
                device, 
                m_buffer_data.staging_buffer, 
                NULL
            );
            vkFreeMemory (
                device, 
                m_buffer_data.staging_buffer_memory, 
                NULL
            );
                
            VkImageViewCreateInfo viewinfo = __vk_ImageCreator::getImageViewInfo (
                tex.image, 
                VK_FORMAT_B8G8R8A8_SRGB, 
                VK_IMAGE_ASPECT_COLOR_BIT,
                mip_levels
            );

            if
            (
                vkCreateImageView (
                    device, 
                    &viewinfo, 
                    NULL, 
                    &tex.image_view
                ) != VK_SUCCESS
            ) VK_RES_ERR("Failed to create texture image view!");

            // Create texture sampler for every texture
            __mkTextureSampler (
                device, 
                tex.sampler,
                mip_levels
            );

            LOG("Created image view and sampler");
        }


        char *__vk_TextureAllocator::__getDummyUUID() { return m_dummy_tex_uuid; }
        

        /*********************************************************/
        /*********************************************************/
        /********** __vk_ResourceManager class methods ***********/
        /*********************************************************/
        /*********************************************************/

        __vk_ResourceManager::__vk_ResourceManager (
            VkDevice device, 
            VkPhysicalDevice gpu, 
            VkExtent2D extent,
            VkSampleCountFlagBits sample_c, 
            VkRenderPass renderpass, 
            VkCommandPool cmd_pool,
            VkQueue g_queue,
            std::vector<VkImageView> sc_img_views,
            const __vk_AssetsInfo &assets_info,
            VkFormat sc_color_format,
            const VkPhysicalDeviceLimits &gpu_limits
        ) : __vk_TextureAllocator (
            device, 
            gpu,
            cmd_pool, 
            g_queue,
            sc_img_views.size(), 
            assets_info.p_tex,
            assets_info.p_tex_map
        ),  m_gpu_limits(gpu_limits) {
            m_p_assets = assets_info.p_assets;
            m_p_textures = assets_info.p_tex;

            m_dummy_tex_uuid = __getDummyUUID();
            LOG("Constructor dummy uuid: " + std::string(m_dummy_tex_uuid));
            m_sample_count = sample_c;
            __allocateUniformBuffer (
                device, 
                gpu,
                cmd_pool,
                g_queue,
                0
            );
            
            __mkColorResources (
                device, 
                gpu, 
                extent, 
                sc_color_format
            );
            
            __mkDepthResources (
                device, 
                gpu, 
                extent
            );

            __mkFrameBuffers (
                device, 
                renderpass, 
                extent, 
                sc_img_views
            );
        }


        /* 
         * Create uniform buffers, but not populate them 
         */
        void __vk_ResourceManager::__allocateUniformBuffer (
            VkDevice device, 
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool, 
            VkQueue g_queue, 
            VkDeviceSize old_size
        ) {
            deng_bool_t is_init = false;
            if(!m_buffer_data.ubo_cap) {
                is_init = true;
                m_buffer_data.ubo_cap = 
                    __max_frame_c * + (
                        __DEFAULT_ASSET_HM_CAP * 
                        std::max(sizeof(__vk_UniformColorData), m_gpu_limits.minUniformBufferOffsetAlignment) +
                        std::max(sizeof(__vk_UniformTransformation), m_gpu_limits.minUniformBufferOffsetAlignment)
                    );
            }

            else {
                // Create staging buffer
                VkMemoryRequirements mem_req = __vk_BufferCreator::makeBuffer (
                    device,
                    gpu,
                    old_size,
                    VK_BUFFER_USAGE_TRANSFER_SRC_BIT, 
                    m_buffer_data.staging_buffer
                );

                // Allocate memory for staging buffer
                __vk_BufferCreator::allocateMemory (
                    device,
                    gpu,
                    mem_req.size,
                    m_buffer_data.staging_buffer_memory,
                    mem_req.memoryTypeBits,
                    VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                    VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
                );

                // Bind staging buffer to its memory
                vkBindBufferMemory (
                    device,
                    m_buffer_data.staging_buffer,
                    m_buffer_data.staging_buffer_memory,
                    0
                );
                
                // Copy uniform buffer data to staging buffer
                __vk_BufferCreator::cpyBufferToBuffer (
                    device,
                    cmd_pool,
                    g_queue,
                    m_buffer_data.uniform_buffer,
                    m_buffer_data.staging_buffer,
                    mem_req.size,
                    0
                );

                // Destroy uniform buffer and its free its memory
                vkDestroyBuffer(device, m_buffer_data.uniform_buffer, NULL);
                vkFreeMemory(device, m_buffer_data.uniform_buffer_mem, NULL);
            }

            VkMemoryRequirements mem_req;

            // Allocate space for uniform data
            mem_req = __vk_BufferCreator::makeBuffer (
                device, 
                gpu, 
                m_buffer_data.ubo_cap, 
                VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT, 
                m_buffer_data.uniform_buffer
            );

            __vk_BufferCreator::allocateMemory (
                device, 
                gpu, 
                mem_req.size, 
                m_buffer_data.uniform_buffer_mem,
                mem_req.memoryTypeBits, 
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | 
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
            );

            vkBindBufferMemory (
                device, 
                m_buffer_data.uniform_buffer,
                m_buffer_data.uniform_buffer_mem,
                0
            );
            
            // In case of creating totally new buffer instance copy default transformation values
            if(is_init) {
                __vk_UniformTransformation ubo;
                ubo.transform.row1 = (dengMath::vec4<deng_vec_t>) {1.0f, 0.0f, 0.0f, 0.0f};
                ubo.transform.row2 = (dengMath::vec4<deng_vec_t>) {0.0f, 1.0f, 0.0f, 0.0f};
                ubo.transform.row3 = (dengMath::vec4<deng_vec_t>) {0.0f, 0.0f, 1.0f, 0.0f};
                ubo.transform.row4 = (dengMath::vec4<deng_vec_t>) {0.0f, 0.0f, 0.0f, 1.0f};

                // These values are temporary
                ubo.flags = DENG_CAMERA_UNIFORM_PERSPECTIVE_CAMERA_MODE_3D |
                            DENG_CAMERA_UNIFORM_NO_CAMERA_MODE_2D;

                // Copy ubo values to ubos
                for(size_t i = 0; i < __max_frame_c; i++) {
                    // Write the initial ubo data to the buffer
                    __vk_BufferCreator::cpyToBufferMem (
                        device,
                        sizeof(__vk_UniformTransformation),
                        &ubo,
                        m_buffer_data.uniform_buffer_mem,
                        i * std::max(sizeof(__vk_UniformTransformation), m_gpu_limits.minUniformBufferOffsetAlignment)
                    );
                    
                }

                // Set the initial ubo offset
                m_buffer_data.ubo_offset = __max_frame_c * std::max(sizeof(__vk_UniformTransformation), m_gpu_limits.minUniformBufferOffsetAlignment);
            }

            // Otherwise copy all data from created staging buffer
            else {
                __vk_BufferCreator::cpyBufferToBuffer (
                    device,
                    cmd_pool,
                    g_queue,
                    m_buffer_data.staging_buffer,
                    m_buffer_data.uniform_buffer,
                    old_size,
                    0
                );

                // Destroy staging buffer instance and free its memory
                vkDestroyBuffer(device, m_buffer_data.staging_buffer, NULL);
                vkFreeMemory(device, m_buffer_data.staging_buffer_memory, NULL);
            }
        }


        /* 
         * Push texture image's color uniform data to uniform buffer
         */
        void __vk_ResourceManager::__pushColorUniformData (
            VkDevice &device,
            VkPhysicalDevice &gpu,
            VkCommandPool &cmd_pool,
            VkQueue g_queue,
            size_t ,
            std::vector<__vk_Texture> &tex_img
        ) {
            // Find new size of the uniform buffer
            VkDeviceSize old_size = m_buffer_data.ubo_cap;
            m_buffer_data.ubo_cap += tex_img.size() * __max_frame_c * sizeof(__vk_UniformColorData);

            // Create and allocate memory for staging buffer 
            VkMemoryRequirements mem_req = __vk_BufferCreator::makeBuffer (
                device,
                gpu,
                old_size,
                VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                m_buffer_data.staging_buffer
            );

            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                mem_req.size,
                m_buffer_data.staging_buffer_memory,
                mem_req.memoryTypeBits,
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
            );

            vkBindBufferMemory (
                device,
                m_buffer_data.staging_buffer,
                m_buffer_data.staging_buffer_memory,
                0
            );

            // Copy the contents from current uniform buffer to staging buffer
            __vk_BufferCreator::cpyBufferToBuffer (
                device,
                cmd_pool,
                g_queue,
                m_buffer_data.uniform_buffer,
                m_buffer_data.staging_buffer,
                old_size,
                0
            );

            // Clean uniform buffer
            vkDestroyBuffer (
                device, 
                m_buffer_data.uniform_buffer, 
                NULL
            );

            vkFreeMemory (
                device,
                m_buffer_data.uniform_buffer_mem,
                NULL
            );

            // Recreate and reallocate memory for uniform buffers
            mem_req = __vk_BufferCreator::makeBuffer (
                device, 
                gpu, 
                m_buffer_data.ubo_cap,
                VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT,
                m_buffer_data.uniform_buffer
            );

            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                mem_req.size,
                m_buffer_data.uniform_buffer_mem,
                mem_req.memoryTypeBits,
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
            );

            vkBindBufferMemory (
                device,
                m_buffer_data.uniform_buffer,
                m_buffer_data.uniform_buffer_mem,
                0
            );

            // Copy data from staging buffer and tex_img color data array to uniform buffer
            __vk_BufferCreator::cpyBufferToBuffer (
                device,
                cmd_pool,
                g_queue,
                m_buffer_data.staging_buffer,
                m_buffer_data.uniform_buffer,
                old_size,
                0
            );
        }
        

        /* 
         * Create new framebuffers 
         */
        void __vk_ResourceManager::__mkFrameBuffers (
            VkDevice &device, 
            VkRenderPass &renderpass, 
            VkExtent2D &extent, 
            std::vector<VkImageView> &sc_img_views
        ) {
            size_t index;
            m_framebuffers.resize(sc_img_views.size());
            std::array<VkImageView, 3> attachments;

            for(index = 0; index < sc_img_views.size(); index++) {
                attachments = {m_color_image_view, m_depth_image_view, sc_img_views[index]};

                VkFramebufferCreateInfo framebuffer_createinfo{};
                framebuffer_createinfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
                framebuffer_createinfo.renderPass = renderpass;
                framebuffer_createinfo.attachmentCount = attachments.size();
                framebuffer_createinfo.pAttachments = attachments.data();
                framebuffer_createinfo.width = extent.width;
                framebuffer_createinfo.height = extent.height;
                framebuffer_createinfo.layers = 1;

                if(vkCreateFramebuffer(device, &framebuffer_createinfo, NULL, &m_framebuffers[index]) != VK_SUCCESS)
                    VK_RES_ERR("failed to create framebuffer!");
                
                else LOG("Framebuffer successfully created");
            }
        }


        /* 
         * Create color resources for multisampling 
         */
        void __vk_ResourceManager::__mkColorResources (
            VkDevice &device,
            VkPhysicalDevice &gpu,
            VkExtent2D &extent,
            VkFormat sc_color_format
        ) {
            VkMemoryRequirements mem_req = __vk_ImageCreator::makeImage (
                device,
                gpu,
                m_color_image,
                extent.width,
                extent.height,
                1,
                sc_color_format,
                VK_IMAGE_TILING_OPTIMAL,
                VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT | 
                VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT,
                m_sample_count
            );

            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                mem_req.size,
                m_color_image_mem,
                mem_req.memoryTypeBits,
                VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
            );

            vkBindImageMemory (
                device,
                m_color_image,
                m_color_image_mem,
                0
            );

            VkImageViewCreateInfo image_view_createinfo = __vk_ImageCreator::getImageViewInfo (
                m_color_image,
                sc_color_format,
                VK_IMAGE_ASPECT_COLOR_BIT,
                1
            );

            if(vkCreateImageView(device, &image_view_createinfo, NULL, &m_color_image_view) != VK_SUCCESS)
                VK_RES_ERR("failed to create color image view");
        }


        /* 
         * Create depth resources for depth buffering 
         */
        void __vk_ResourceManager::__mkDepthResources (
            VkDevice &device, 
            VkPhysicalDevice &gpu, 
            VkExtent2D &extent
        ) {
            VkMemoryRequirements mem_req = __vk_ImageCreator::makeImage (
                device, 
                gpu, 
                m_depth_image, 
                extent.width, 
                extent.height, 
                1,
                VK_FORMAT_D32_SFLOAT, 
                VK_IMAGE_TILING_OPTIMAL, 
                VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT,
                m_sample_count
            );
            
            __vk_BufferCreator::allocateMemory (
                device, 
                gpu, 
                mem_req.size,
                m_depth_image_mem,  
                mem_req.memoryTypeBits, 
                VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
            );

            vkBindImageMemory (
                device, 
                m_depth_image, 
                m_depth_image_mem, 
                0
            );

            VkImageViewCreateInfo image_view_createinfo = __vk_ImageCreator::getImageViewInfo (
                m_depth_image, 
                VK_FORMAT_D32_SFLOAT, 
                VK_IMAGE_ASPECT_DEPTH_BIT,
                1
            );

            if(vkCreateImageView(device, &image_view_createinfo, NULL, &m_depth_image_view) != VK_SUCCESS)
                VK_RES_ERR("failed to create depth image view!");
        }




        /* 
         * Set up texture image buffers, samplers and mipmaps if they
         * are supported
         */
        void __vk_ResourceManager::mkTextures (
            VkDevice device, 
            VkPhysicalDevice gpu, 
            VkCommandPool cmd_pool,
            deng_bool_t is_lf, 
            dengMath::vec2<deng_ui32_t> tex_bounds,
            VkQueue g_queue
        ) {
            size_t index;
            deng_ui32_t mip_levels = 1;

            // Iterate through assets an check if it is texture mapped
            for(index = tex_bounds.first; index < tex_bounds.second; index++) {
                // Check if mipmapping is supported
                if(is_lf) {
                    mip_levels = (deng_i32_t) floor (
                        log2 (
                            std::max (
                                (*m_p_textures)[index].texture.pixel_data.width, 
                                (*m_p_textures)[index].texture.pixel_data.height
                            )
                        )
                    ) + 1;
                }

                else mip_levels = 1;
                
                __newImage (
                    device,
                    gpu,
                    cmd_pool,
                    g_queue,
                    mip_levels,
                    is_lf,
                    m_p_textures->at(index)
                );
            }
        }


        /* 
         * Create and populate main data buffer with asset
         * vertices and indices
         */
        void __vk_ResourceManager::mkBuffers (
            VkDevice device, 
            VkPhysicalDevice gpu, 
            VkCommandPool cmd_pool, 
            VkQueue g_queue
        ) {
            size_t i;
            VkDeviceSize cur_offset = 0;
            m_buffer_data.main_buffer_size = 0;
            VkMemoryRequirements mem_req;

            // Find the total amount of bytes needed to allocate for assets 
            for(i = 0; i < m_p_assets->size(); i++) {
                (*m_p_assets)[i].asset.vertices.mem_offset = m_buffer_data.main_buffer_size;

                switch ((*m_p_assets)[i].asset.asset_mode)
                {
                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_UNOR);
                    break;

                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED_NORMALISED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_NOR);
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_UNOR);
                    break;
                
                case DAS_ASSET_MODE_3D_UNMAPPED_NORMALISED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_NOR);
                    break;

                case DAS_ASSET_MODE_2D_TEXTURE_MAPPED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_2D);
                    break;

                case DAS_ASSET_MODE_2D_UNMAPPED:
                    m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_2D);
                    break;
                
                default:
                    break;
                }

                // Add indices to the buffer byte count
                (*m_p_assets)[i].asset.indices.mem_offset = m_buffer_data.main_buffer_size;
                m_buffer_data.main_buffer_size += (*m_p_assets)[i].asset.indices.n * sizeof(deng_ui32_t);
            }


            LOG("Main buffer size is: " + std::to_string(m_buffer_data.main_buffer_size));
            
            // Create and allocate memory for staging buffer
            mem_req = __vk_BufferCreator::makeBuffer (
                device, 
                gpu, 
                m_buffer_data.main_buffer_size, 
                VK_BUFFER_USAGE_TRANSFER_SRC_BIT, 
                m_buffer_data.staging_buffer
            );

            __vk_BufferCreator::allocateMemory (
                device, 
                gpu, 
                mem_req.size,
                m_buffer_data.staging_buffer_memory,  
                mem_req.memoryTypeBits, 
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT | 
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
            );

            vkBindBufferMemory (
                device, 
                m_buffer_data.staging_buffer, 
                m_buffer_data.staging_buffer_memory, 
                0
            );
            
            // Assign correct offsets for buffers and populate buffer memory
            for(i = 0, m_buffer_data.main_buffer_size = 0; i < m_p_assets->size(); i++) {
                // Populate staging buffer memory with vertices data
                switch ((*m_p_assets)[i].asset.asset_mode)
                {
                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED:
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_UNOR);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vmu, 
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;

                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED_NORMALISED:
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_NOR);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vmn, 
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED:
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_UNOR);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vuu, 
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED_NORMALISED:
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_NOR);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vun, 
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;

                case DAS_ASSET_MODE_2D_TEXTURE_MAPPED:
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_MAPPED_2D);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vm2d, 
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;

                case DAS_ASSET_MODE_2D_UNMAPPED: {
                    cur_offset = (*m_p_assets)[i].asset.vertices.n * sizeof(VERT_UNMAPPED_2D);
                    __vk_BufferCreator::cpyToBufferMem (
                        device, 
                        cur_offset, 
                        (*m_p_assets)[i].asset.vertices.vu2d,
                        m_buffer_data.staging_buffer_memory, 
                        m_buffer_data.main_buffer_size
                    );
                    break;
                }

                default:
                    break;
                }

                m_buffer_data.main_buffer_size += cur_offset;

                // Populate staging memory with indices data
                cur_offset = (*m_p_assets)[i].asset.indices.n * sizeof(deng_ui32_t);
                __vk_BufferCreator::cpyToBufferMem (
                    device, 
                    cur_offset, 
                    (*m_p_assets)[i].asset.indices.indices, 
                    m_buffer_data.staging_buffer_memory, 
                    m_buffer_data.main_buffer_size
                );

                m_buffer_data.main_buffer_size += cur_offset;
            }

            // Push data from staging buffer to main buffer
            mem_req = __vk_BufferCreator::makeBuffer (
                device, 
                gpu, 
                m_buffer_data.main_buffer_size, 
                VK_BUFFER_USAGE_VERTEX_BUFFER_BIT | 
                VK_BUFFER_USAGE_INDEX_BUFFER_BIT | 
                VK_BUFFER_USAGE_TRANSFER_DST_BIT, 
                m_buffer_data.main_buffer
            );

            __vk_BufferCreator::allocateMemory (
                device, 
                gpu, 
                mem_req.size, 
                m_buffer_data.main_buffer_memory, 
                mem_req.memoryTypeBits, 
                VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
            );

            vkBindBufferMemory (
                device, 
                m_buffer_data.main_buffer, 
                m_buffer_data.main_buffer_memory, 
                0
            );

            __vk_BufferCreator::cpyBufferToBuffer (
                device, 
                cmd_pool, 
                g_queue, 
                m_buffer_data.staging_buffer, 
                m_buffer_data.main_buffer, 
                m_buffer_data.main_buffer_size, 
                0
            );

            // Perform staging buffer cleanup
            vkDestroyBuffer(device, m_buffer_data.staging_buffer, NULL);
            vkFreeMemory(device, m_buffer_data.staging_buffer_memory, NULL);
        }


        /*
         * This method either doubles the texture buffer memory capacity or 
         * calculates the new capacity from given textures and 
         * reallocates everything in it.
         */
        void __vk_ResourceManager::__reallocateTextureMemory (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue
        ) {
            // Find out how much memory needs to be allocated
            size_t req_size = 0;
            size_t old_size = m_buffer_data.img_memory_cap;
            for(size_t i = 0; i < m_p_textures->size(); i++)
                req_size += m_p_textures->at(i).texture.pixel_data.size;
            
            // Check how much the memory capacity should be incremented
            if(req_size > m_buffer_data.img_memory_cap * 2) {
                // Round the to the closest biggest base 2 exponent
                m_buffer_data.img_memory_cap = req_size;
                deng_f64_t exp = ceil(log2((deng_f64_t) m_buffer_data.img_memory_cap));

                m_buffer_data.img_memory_cap = (VkDeviceSize) pow(2.0, exp);
            }

            else m_buffer_data.img_memory_cap *= 2;
            
            // Destroy all previously created VkImage instances
            for(size_t i = 0; i < m_p_textures->size(); i++) {
                vkDestroyImageView (
                    device, 
                    m_p_textures->at(i).image_view, 
                    NULL
                );

                vkDestroyImage (
                    device, 
                    m_p_textures->at(i).image, 
                    NULL
                );
            }
                
            __allocateTexMemory (
                device, 
                gpu, 
                cmd_pool, 
                g_queue, 
                old_size, 
                req_size
            );
        }


        /*
         * This method reallocates ubo buffer to double its current capacity
         */
        void __vk_ResourceManager::__reallocateUniformBufferMemory (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue
        ) {
            VkDeviceSize old_size = m_buffer_data.ubo_cap;
            m_buffer_data.ubo_cap *= 2;
            
            __allocateUniformBuffer (
                device,
                gpu,
                cmd_pool,
                g_queue,
                old_size
            );
        }


        /* 
         * Update camera uniform data buffer 
         */
        void __vk_ResourceManager::updateUniformData (
            VkDevice device, 
            deng_ui32_t current_image, 
            deng_ui32_t img_c,
            Camera3D *p_cam,
            deng_bool_t update_tex,
            const dengMath::vec2<deng_ui32_t> &tex_bounds,
            deng_CameraUniformFlagBits flag_bits
        ) {
            __vk_UniformTransformation ubo;
            ubo.flags = flag_bits;
            ubo.transform = p_cam->getCameraMat();   
            ubo.view = p_cam->getViewMat();
            ubo.flags = DENG_CAMERA_UNIFORM_NO_CAMERA_MODE_2D |
                        DENG_CAMERA_UNIFORM_PERSPECTIVE_CAMERA_MODE_3D;

            __vk_BufferCreator::cpyToBufferMem (
                device,
                sizeof(__vk_UniformTransformation),
                &ubo,
                m_buffer_data.uniform_buffer_mem,
                current_image * std::max(sizeof(__vk_UniformTransformation), m_gpu_limits.minUniformBufferOffsetAlignment)
            );
        }


        /*
         * Copy asset color data to uniform buffer memory
         * PS! ubo_mem pointer must have enough memory allocated for copying
         * data to it 
         */
        void __vk_ResourceManager::reserveAssetUniformData (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue,
            __vk_UniformColorData *ubo_mem,
            __vk_Asset &asset
        ) {
            asset.color_offset = m_buffer_data.ubo_offset;
            LOG("Color offset " + std::to_string(asset.color_offset));
            __vk_UniformColorData ubo;
            ubo.color = (dengMath::vec4<deng_vec_t>) {
                asset.asset.color.col_r,
                asset.asset.color.col_g,
                asset.asset.color.col_b,
                asset.asset.color.col_a
            };
            
            // Check if asset type is unmapped or not
            if (
                asset.asset.asset_mode == DAS_ASSET_MODE_2D_UNMAPPED ||
                asset.asset.asset_mode == DAS_ASSET_MODE_3D_UNMAPPED ||
                asset.asset.asset_mode == DAS_ASSET_MODE_3D_UNMAPPED_NORMALISED
            ) ubo.is_unmapped = true;
            else ubo.is_unmapped = asset.asset.force_unmap; 

            for(size_t i = 0; i < __max_frame_c; i++) {
                // Check if buffer memory needs to be reallocated
                if (
                    asset.color_offset + i * std::max (
                        sizeof(__vk_UniformColorData), 
                        m_gpu_limits.minUniformBufferOffsetAlignment
                    ) > m_buffer_data.ubo_cap
                ) {
                    __reallocateTextureMemory (
                        device,
                        gpu,
                        cmd_pool,
                        g_queue
                    );
                }

                // Copy all data to buffer
                __vk_BufferCreator::cpyToBufferMem (
                    device,
                    sizeof(__vk_UniformColorData),
                    &ubo,
                    m_buffer_data.uniform_buffer_mem,
                    asset.color_offset + i * std::max(sizeof(__vk_UniformColorData), m_gpu_limits.minUniformBufferOffsetAlignment)
                );
            }
            m_buffer_data.ubo_offset += __max_frame_c * std::max(sizeof(__vk_UniformColorData), m_gpu_limits.minUniformBufferOffsetAlignment);
        }


        /*
         * Replace data in main buffer with newer data from given asset vertices
         */
        void __vk_ResourceManager::remapAssetVerts (
            VkDevice device,
            VkPhysicalDevice gpu,
            VkCommandPool cmd_pool,
            VkQueue g_queue,
            dengMath::vec2<deng_ui32_t> asset_bounds
        ) {
            // Verify asset bounds
            if(asset_bounds.first >= m_p_assets->size() || asset_bounds.second > m_p_assets->size()) 
                RUN_ERR("remapAssetVerts(): Invalid asset vertices bounds!");
            
            // Find maximum vertex memory usage
            VkDeviceSize max_mem = 0;
            for(size_t i = asset_bounds.first; i < asset_bounds.second; i++) {
                switch(m_p_assets->at(i).asset.asset_mode) 
                {
                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_UNOR))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_UNOR);
                    break;

                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED_NORMALISED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_NOR))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_NOR);
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_UNOR))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_UNOR);
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED_NORMALISED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_NOR))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_NOR);
                    break;

                case DAS_ASSET_MODE_2D_UNMAPPED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_2D))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_2D);
                    break;

                case DAS_ASSET_MODE_2D_TEXTURE_MAPPED:
                    if(max_mem < m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_2D))
                        max_mem = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_2D);
                    break;

                default:
                    break;
                }
            }

            // Allocate memory for staging buffer
            VkMemoryRequirements mem_req;
            mem_req = __vk_BufferCreator::makeBuffer (
                device,
                gpu,
                max_mem,
                VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                m_buffer_data.staging_buffer

            );

            __vk_BufferCreator::allocateMemory (
                device,
                gpu,
                mem_req.size,
                m_buffer_data.staging_buffer_memory,
                mem_req.memoryTypeBits,
                VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
            );

            vkBindBufferMemory (
                device,
                m_buffer_data.staging_buffer,
                m_buffer_data.staging_buffer_memory,
                0
            );

            // Update main buffer 
            VkDeviceSize offset = 0;
            VkDeviceSize size = 0;
            for(size_t i = asset_bounds.first; i < asset_bounds.second; i++) {
                switch(m_p_assets->at(i).asset.asset_mode) 
                {
                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_UNOR);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vmu,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                case DAS_ASSET_MODE_3D_TEXTURE_MAPPED_NORMALISED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_NOR);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vmn,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_UNOR);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vuu,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                case DAS_ASSET_MODE_3D_UNMAPPED_NORMALISED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_NOR);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vun,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                case DAS_ASSET_MODE_2D_UNMAPPED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_UNMAPPED_2D);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vu2d,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                case DAS_ASSET_MODE_2D_TEXTURE_MAPPED:
                    offset = m_p_assets->at(i).asset.vertices.mem_offset;
                    size = m_p_assets->at(i).asset.vertices.n * sizeof(VERT_MAPPED_2D);

                    __vk_BufferCreator::cpyToBufferMem ( 
                        device,
                        size,
                        m_p_assets->at(i).asset.vertices.vm2d,
                        m_buffer_data.staging_buffer_memory,
                        0 
                    );
                    break;

                default:
                    break;
                }


                __vk_BufferCreator::cpyBufferToBuffer (
                    device,
                    cmd_pool,
                    g_queue,
                    m_buffer_data.staging_buffer,
                    m_buffer_data.main_buffer,
                    size,
                    offset
                );
            }

            vkDestroyBuffer(device, m_buffer_data.staging_buffer, NULL);
            vkFreeMemory(device, m_buffer_data.staging_buffer_memory, NULL);
        }


        /* __vk_ResourceManager class getters */
        __vk_BufferData *__vk_ResourceManager::getBD() { return &m_buffer_data; }
        std::vector<VkFramebuffer> __vk_ResourceManager::getFB() { return m_framebuffers; }
        char *__vk_ResourceManager::getDummyTexUUID() { return m_dummy_tex_uuid; }
        VkImage __vk_ResourceManager::getDepImg() { return m_depth_image; }
        VkDeviceMemory __vk_ResourceManager::getDepImgMem() { return m_depth_image_mem; }
        VkImageView __vk_ResourceManager::getDepImgView() { return m_depth_image_view; }
        VkImage __vk_ResourceManager::getColorImg() { return m_color_image; }
        VkDeviceMemory __vk_ResourceManager::getColorImgMem() { return m_color_image_mem; }
        VkImageView __vk_ResourceManager::getColorImgView() { return m_color_image_view; }
    }
}
